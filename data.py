import pandas as pd
from groq import Groq
from sqlalchemy import create_engine, text
import os
import json
import hashlib
from typing import Optional, List, Dict

class HealthRAGSystem:
    def __init__(self, groq_api_key: str):
        self.groq_client = Groq(api_key=groq_api_key)
        
        # Streamlit secretsì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        try:
            import streamlit as st
            self.db_config = {
                'DB_NAME': st.secrets["DB_NAME"],
                'DB_USER': st.secrets["DB_USER"],
                'DB_PASS': st.secrets["DB_PASS"],
                'DB_HOST': st.secrets["DB_HOST"],
                'DB_PORT': st.secrets["DB_PORT"]
            }
        except (KeyError, ImportError):
            # ë¡œì»¬ ê°œë°œìš© fallback
            self.db_config = {
                'DB_NAME': os.getenv('DB_NAME', 'Amway_DB'),
                'DB_USER': os.getenv('DB_USER', 'postgres'),
                'DB_PASS': os.getenv('DB_PASS', '990910'),
                'DB_HOST': os.getenv('DB_HOST', 'localhost'),
                'DB_PORT': os.getenv('DB_PORT', '5432')
            }
        
        conn_str = f"postgresql+psycopg2://{self.db_config['DB_USER']}:{self.db_config['DB_PASS']}@{self.db_config['DB_HOST']}:{self.db_config['DB_PORT']}/{self.db_config['DB_NAME']}"
        self.engine = create_engine(conn_str)
        # LLM ì‘ë‹µ ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.cache_dir = os.path.join(os.getcwd(), ".llm_cache")
        os.makedirs(self.cache_dir, exist_ok=True)

    # --------------------------
    # ìºì‹± ìœ í‹¸ë¦¬í‹°
    # --------------------------
    def _stable_serialize(self, data: Dict) -> str:
        """ë”•ì…”ë„ˆë¦¬ë¥¼ ì •ë ¬ëœ JSON ë¬¸ìì—´ë¡œ ì§ë ¬í™”(í•œê¸€ ë³´ì¡´)."""
        return json.dumps(data, ensure_ascii=False, sort_keys=True, separators=(",", ":"))

    def _build_cache_key(self, payload: Dict, prefix: str) -> str:
        serialized = self._stable_serialize(payload).encode("utf-8")
        digest = hashlib.sha256(serialized).hexdigest()
        return f"{prefix}-{digest}"

    def _read_cache(self, key: str) -> Optional[str]:
        path = os.path.join(self.cache_dir, f"{key}.json")
        if not os.path.exists(path):
            return None
        try:
            with open(path, "r", encoding="utf-8") as f:
                obj = json.load(f)
            return obj.get("content")
        except Exception:
            return None

    def _write_cache(self, key: str, content: str) -> None:
        path = os.path.join(self.cache_dir, f"{key}.json")
        try:
            with open(path, "w", encoding="utf-8") as f:
                json.dump({"content": content}, f, ensure_ascii=False)
        except Exception:
            pass

    def get_products_from_classification(self, health_indicators: List[str], physiology_network: List[str], health_concerns: List[str]) -> tuple:
        """ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸”ì—ì„œ ê±´ê°•ì§€í‘œ ì¡°í•©ì— ë§ëŠ” ì œí’ˆë“¤ì„ ê°€ì ¸ì˜¤ê³  ìš°ì„ ìˆœìœ„ë¥¼ ì ìš© - ìµœì¢… ìµœì í™” ë²„ì „"""
        
        if not health_indicators:
            return [], {}
        
        # ì „ì²´ í…Œì´ë¸” ì¡°íšŒ (ì•ˆì •ì„± ìš°ì„ ) - ì›ë£Œ ì»¬ëŸ¼ ì¶”ê°€
        query = """
        SELECT "ì œí’ˆëª…", "ê±´ê°•ì§€í‘œ", "ê´€ë¦¬ í•„ìš” ì˜ì—­", "ì›ë£Œ"
        FROM "ë¶„ë¥˜ê¸°ì¤€"
        ORDER BY "ì œí’ˆëª…", "ê±´ê°•ì§€í‘œ"
        """
        
        try:
            classification_df = pd.read_sql(query, con=self.engine)
        except Exception as e:
            return [], {}
        
        if classification_df.empty:
            return [], {}
        
        # ì§‘í•© ì—°ì‚° ìµœì í™”
        health_indicators_set = set(health_indicators)
        physiology_set = set(physiology_network)
        concerns_set = set(health_concerns)
        all_selected_areas = physiology_set | concerns_set
        
        # ì œí’ˆë³„ ë°ì´í„° êµ¬ì¡°í™”
        product_data = {}
        
        for _, row in classification_df.iterrows():
            product_name = row['ì œí’ˆëª…']
            health_indicator_combo = row['ê±´ê°•ì§€í‘œ']
            management_area = row['ê´€ë¦¬ í•„ìš” ì˜ì—­']
            
            if product_name not in product_data:
                product_data[product_name] = {
                    'combos': [],
                    'areas': set(),
                    'physiology_matches': 0,
                    'concern_matches': 0
                }
            
            product_data[product_name]['combos'].append(health_indicator_combo)
            product_data[product_name]['areas'].add(management_area)
            
            # ê´€ë¦¬ì˜ì—­ ë§¤ì¹­ ì¹´ìš´íŠ¸
            if management_area in physiology_set:
                product_data[product_name]['physiology_matches'] += 1
            if management_area in concerns_set:
                product_data[product_name]['concern_matches'] += 1
        
        # ê° ì œí’ˆì˜ ìµœì  ì¡°í•© ì°¾ê¸°
        final_products = []
        
        for product_name, data in product_data.items():
            best_match_count = 0
            best_combo = ''
            best_combo_size = float('inf')
            best_is_exact = False
            
            for combo in data['combos']:
                combo_indicators = [ind.strip() for ind in combo.split(',')]
                combo_set = set(combo_indicators)
                
                # ë§¤ì¹­ ê³„ì‚°
                match_count = len(combo_set & health_indicators_set)
                if match_count == 0:
                    continue
                
                combo_size = len(combo_set)
                is_exact_match = combo_set.issubset(health_indicators_set)
                
                # ìš°ì„ ìˆœìœ„ ê²°ì •: ì •í™•í•œ ë§¤ì¹­ > ë§¤ì¹­ ê°œìˆ˜ > ì¡°í•© í¬ê¸° ì‘ìŒ
                is_better = False
                if is_exact_match and not best_is_exact:
                    is_better = True
                elif is_exact_match == best_is_exact:
                    if match_count > best_match_count:
                        is_better = True
                    elif match_count == best_match_count and combo_size < best_combo_size:
                        is_better = True
                
                if is_better:
                    best_match_count = match_count
                    best_combo = combo
                    best_combo_size = combo_size
                    best_is_exact = is_exact_match
            
            if best_match_count > 0:
                # ê´€ë¦¬ì˜ì—­ ë§¤ì¹­ ì ìˆ˜ (ë‚®ì€ ê°€ì¤‘ì¹˜)
                area_matches = len(data['areas'] & all_selected_areas)
                area_score = area_matches if all_selected_areas else 0
                
                # ìµœì¢… ì ìˆ˜ ê³„ì‚° - ê±´ê°•ì§€í‘œ ì •í™•ì„± ì ˆëŒ€ ìš°ì„ 
                if best_is_exact:
                    # ì •í™•í•œ ë§¤ì¹­: ì¡°í•© í¬ê¸°ê°€ ì‘ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
                    combo_bonus = max(0, 10 - best_combo_size) * 100
                    final_score = 10000 + best_match_count * 1000 + combo_bonus + area_score
                else:
                    # ë¶€ì •í™•í•œ ë§¤ì¹­: ë‚®ì€ ê¸°ë³¸ ì ìˆ˜
                    final_score = best_match_count * 100 + area_score
                
                final_products.append((
                    product_name,
                    {
                        'best_match_count': best_match_count,
                        'best_combo': best_combo,
                        'best_combo_size': best_combo_size,
                        'best_is_exact_match': best_is_exact,
                        'physiology_matches': data['physiology_matches'],
                        'concern_matches': data['concern_matches'],
                        'management_areas': data['areas'],
                        'final_score': final_score
                    }
                ))
        
        # ì ìˆ˜ìˆœ ì •ë ¬ ë° ìƒìœ„ 7ê°œ ì„ íƒ
        final_products.sort(key=lambda x: x[1]['final_score'], reverse=True)
        top_products = final_products[:7]
        
        selected_products = [p[0] for p in top_products]
        product_scores = {p[0]: p[1] for p in top_products}
        
        return selected_products, product_scores

    def get_product_details(self, product_names: List[str]) -> pd.DataFrame:
        """ì œí’ˆì •ë³´ì™€ ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸”ì—ì„œ ì œí’ˆ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        if not product_names:
            return pd.DataFrame()
        
        product_filter = ', '.join(f"'{name}'" for name in product_names)
        
        # ì œí’ˆì •ë³´ í…Œì´ë¸”ì—ì„œ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ (ì œí’ˆëª…, ê´€ë¦¬ í•„ìš” ì˜ì—­ ì œì™¸)
        query = f"""
        SELECT DISTINCT
            pi."ì‹í’ˆìœ í˜•",
            pi."ì œí’ˆëª…",
            pi."ì‹ì•½ì²˜ ì¸ì • ê¸°ëŠ¥ì„±",
            pi."ì£¼ìš” íŠ¹ì§•",
            pi."ì„­ì·¨ ë°©ë²•",
            pi."ì£¼ì˜ì‚¬í•­",
            pi."ì›ì¬ë£Œ",
            pi."ì˜ì–‘ì„±ë¶„",
            pi."ê¸€ë¡œë²Œ/ë¡œì»¬ ì œí’ˆêµ¬ë¶„(ì œì¡°ì‚¬)",
            al."ì•Œë ˆë¥´ê²_ì •ë³´"
        FROM "ì œí’ˆì •ë³´" pi
        LEFT JOIN (
            SELECT "ì œí’ˆëª…", STRING_AGG("ì¹´í…Œê³ ë¦¬" || ' - ' || "ë¶„ë¥˜" || ' (' || "ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ" || ')', ', ') AS ì•Œë ˆë¥´ê²_ì •ë³´
            FROM "ì œí’ˆ_ì•Œë ˆë¥´ê²"
            GROUP BY "ì œí’ˆëª…"
        ) al ON pi."ì œí’ˆëª…" = al."ì œí’ˆëª…"
        WHERE pi."ì œí’ˆëª…" IN ({product_filter})
        """
        
        product_info_df = pd.read_sql(query, con=self.engine)
        
        # ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸”ì—ì„œ ê´€ë¦¬ í•„ìš” ì˜ì—­ ì¡°íšŒ
        classification_query = f"""
        SELECT "ì œí’ˆëª…", STRING_AGG(DISTINCT "ê´€ë¦¬ í•„ìš” ì˜ì—­", ', ') as "ê´€ë¦¬ í•„ìš” ì˜ì—­"
        FROM "ë¶„ë¥˜ê¸°ì¤€"
        WHERE "ì œí’ˆëª…" IN ({product_filter})
        GROUP BY "ì œí’ˆëª…"
        """
        
        classification_df = pd.read_sql(classification_query, con=self.engine)
        
        # ë‘ DataFrameì„ ì œí’ˆëª…ìœ¼ë¡œ ë³‘í•©
        if not product_info_df.empty and not classification_df.empty:
            result_df = pd.merge(product_info_df, classification_df, on='ì œí’ˆëª…', how='left')
        else:
            result_df = product_info_df
        
        return result_df

    def get_product_classification_info(self, product_names: List[str]) -> Dict[str, Dict]:
        """ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸”ì—ì„œ ì œí’ˆë³„ ê±´ê°•ì§€í‘œì™€ ê´€ë¦¬ í•„ìš” ì˜ì—­ ì •ë³´ ì¡°íšŒ"""
        if not product_names:
            return {}
        
        product_filter = ', '.join(f"'{name}'" for name in product_names)
        
        query = f"""
        SELECT "ì œí’ˆëª…", "ê±´ê°•ì§€í‘œ", "ê´€ë¦¬ í•„ìš” ì˜ì—­", "ì›ë£Œ"
        FROM "ë¶„ë¥˜ê¸°ì¤€"
        WHERE "ì œí’ˆëª…" IN ({product_filter})
        """
        
        classification_df = pd.read_sql(query, con=self.engine)
        
        # ì œí’ˆë³„ë¡œ ê±´ê°•ì§€í‘œ, ê´€ë¦¬ í•„ìš” ì˜ì—­, ì›ë£Œ ê·¸ë£¹í™”
        product_classification = {}
        for _, row in classification_df.iterrows():
            product_name = row['ì œí’ˆëª…']
            if product_name not in product_classification:
                product_classification[product_name] = {
                    'health_indicators': set(),
                    'management_areas': set(),
                    'ingredients': set()
                }
            
            product_classification[product_name]['health_indicators'].add(row['ê±´ê°•ì§€í‘œ'])
            product_classification[product_name]['management_areas'].add(row['ê´€ë¦¬ í•„ìš” ì˜ì—­'])
            
            # ì›ë£Œ ì •ë³´ ì¶”ê°€ (nullì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
            if pd.notna(row.get('ì›ë£Œ')):
                product_classification[product_name]['ingredients'].add(row['ì›ë£Œ'])
        
        return product_classification

    def get_health_indicator_relationships(self) -> Dict[str, List[str]]:
        """ê·¸ë˜í”„ í…Œì´ë¸”ì—ì„œ ê±´ê°•ì§€í‘œì™€ ê´€ë¦¬ í•„ìš” ì˜ì—­ì˜ ì—°ê´€ ê´€ê³„ ì¡°íšŒ"""
        query = """
        SELECT DISTINCT "ê±´ê°•ì§€í‘œ", "ê´€ë¦¬ í•„ìš” ì˜ì—­"
        FROM "ê·¸ë˜í”„"
        WHERE "ê±´ê°•ì§€í‘œ" IS NOT NULL AND "ê´€ë¦¬ í•„ìš” ì˜ì—­" IS NOT NULL
        """
        
        graph_df = pd.read_sql(query, con=self.engine)
        
        # ê±´ê°•ì§€í‘œë³„ë¡œ ê´€ë¦¬ í•„ìš” ì˜ì—­ë“¤ì„ ê·¸ë£¹í™”
        health_relationships = {}
        for _, row in graph_df.iterrows():
            health_indicator = row['ê±´ê°•ì§€í‘œ']
            management_area = row['ê´€ë¦¬ í•„ìš” ì˜ì—­']
            
            if health_indicator not in health_relationships:
                health_relationships[health_indicator] = []
            
            if management_area not in health_relationships[health_indicator]:
                health_relationships[health_indicator].append(management_area)
        
        return health_relationships

    def create_health_status_explanation(self, assessments: Dict[str, str], physiology_network: List[str], health_concerns: List[str], recommended_products_df: pd.DataFrame = None) -> str:
        """ì‚¬ìš©ìì˜ ê±´ê°• ìƒíƒœì— ëŒ€í•œ ì„¤ëª… í…ìŠ¤íŠ¸ ìƒì„±"""
        
        # ê·¸ë˜í”„ í…Œì´ë¸”ì—ì„œ ê±´ê°•ì§€í‘œì™€ ê´€ë¦¬ í•„ìš” ì˜ì—­ ì—°ê´€ ê´€ê³„ ì¡°íšŒ
        health_relationships = self.get_health_indicator_relationships()
        
        # 'ì¢‹ìŒ'ì´ ì•„ë‹Œ ê±´ê°•ì§€í‘œë§Œ í•„í„°ë§
        problematic_indicators = {k: v for k, v in assessments.items() if v in ["ì£¼ì˜", "ê´€ë¦¬"]}
        
        if not problematic_indicators:
            return ""
        
        explanation_parts = []
        
        # ì „ì²´ ìƒíƒœ ìš”ì•½ì„ ë” ë¶€ë“œëŸ½ê³  ìì„¸í•˜ê²Œ ì‘ì„±
        explanation_parts.append(f"**ğŸ” ê±´ê°• ìƒíƒœ ë¶„ì„**")
        explanation_parts.append("")
        
        # ì£¼ì˜/ê´€ë¦¬ê°€ í•„ìš”í•œ ì§€í‘œë“¤ ë¶„ì„
        attention_indicators = [k for k, v in problematic_indicators.items() if v == "ì£¼ì˜"]
        management_indicators = [k for k, v in problematic_indicators.items() if v == "ê´€ë¦¬"]
        
        # ì¶”ì²œëœ ì œí’ˆë“¤ì˜ ê´€ë¦¬ í•„ìš” ì˜ì—­ ìˆ˜ì§‘
        all_product_areas = set()
        if recommended_products_df is not None and not recommended_products_df.empty:
            for _, row in recommended_products_df.iterrows():
                # ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸”ì˜ ê´€ë¦¬ í•„ìš” ì˜ì—­
                if row.get('í•´ë‹¹_ê´€ë¦¬ì˜ì—­'):
                    areas_from_classification = [area.strip() for area in row['í•´ë‹¹_ê´€ë¦¬ì˜ì—­'].split(',')]
                    all_product_areas.update(areas_from_classification)
                
                # ì œí’ˆì •ë³´ í…Œì´ë¸”ì˜ ê´€ë¦¬ í•„ìš” ì˜ì—­
                if row.get('ê´€ë¦¬ í•„ìš” ì˜ì—­'):
                    areas_from_product_info = [area.strip() for area in row['ê´€ë¦¬ í•„ìš” ì˜ì—­'].split(',')]
                    all_product_areas.update(areas_from_product_info)
        
        # ì‚¬ìš©ìê°€ ì„ íƒí•œ ì˜ì—­ê³¼ ì œí’ˆ ê´€ë¦¬ ì˜ì—­ì˜ êµì§‘í•©
        all_selected_areas = set(physiology_network + health_concerns)
        priority_areas = []
        
        # ê° ê±´ê°•ì§€í‘œì™€ ì—°ê´€ëœ ì˜ì—­ ì¤‘ì—ì„œ ì‚¬ìš©ìê°€ ì„ íƒí•œ ê²ƒë“¤ê³¼ ì œí’ˆ ì˜ì—­ë“¤ ì°¾ê¸°
        for indicator in problematic_indicators.keys():
            if indicator in health_relationships:
                related_areas = health_relationships[indicator]
                matching_areas = [area for area in related_areas if area in all_selected_areas or area in all_product_areas]
                priority_areas.extend(matching_areas)
        
        # ì¤‘ë³µ ì œê±°í•˜ê³  ìš°ì„ ìˆœìœ„ ì˜ì—­ ì„ íƒ (ìµœëŒ€ 2ê°œ)
        unique_priority_areas = list(set(priority_areas))[:2]
        
        # ë¶€ë“œëŸ¬ìš´ í†¤ìœ¼ë¡œ ê±´ê°• ìƒíƒœ ì„¤ëª… (ë” ìì„¸í•˜ê²Œ)
        status_description = "ì‚¬ìš©ìë‹˜ì€ ìµœê·¼ ê±´ê°•ì ìˆ˜ì—ì„œ "
        
        if attention_indicators and management_indicators:
            status_description += f"{', '.join(attention_indicators + management_indicators)}ëŠ” ê°ê° 'ì£¼ì˜'ì™€ 'ê´€ë¦¬'ë¡œ ë‚˜íƒ€ë‚˜ "
        elif attention_indicators:
            status_description += f"{', '.join(attention_indicators)}ëŠ” 'ì£¼ì˜'ë¡œ ë‚˜íƒ€ë‚˜ "
        elif management_indicators:
            status_description += f"{', '.join(management_indicators)}ëŠ” 'ê´€ë¦¬'ë¡œ ë‚˜íƒ€ë‚˜ "
        
        if unique_priority_areas:
            status_description += f"**{', '.join(unique_priority_areas)} ê´€ë¦¬**ê°€ ìš°ì„ ì…ë‹ˆë‹¤."
        else:
            status_description += "ì „ë°˜ì ì¸ ê±´ê°• ê´€ë¦¬ê°€ í•„ìš”í•œ ìƒíƒœì…ë‹ˆë‹¤."
        
        explanation_parts.append(status_description)
        explanation_parts.append("")
        
        # ë” ìì„¸í•œ ê±´ê°• ìƒíƒœ ë¶„ì„ ì¶”ê°€
        detailed_analysis = []
        
        # ê° ê±´ê°•ì§€í‘œë³„ ìƒì„¸ ë¶„ì„
        for indicator, status in problematic_indicators.items():
            if indicator in health_relationships:
                related_areas = health_relationships[indicator]
                # í•´ë‹¹ ê±´ê°•ì§€í‘œì™€ ì—°ê´€ëœ ì˜ì—­ ì¤‘ ì œí’ˆì´ë‚˜ ì‚¬ìš©ì ì„ íƒê³¼ ë§¤ì¹­ë˜ëŠ” ê²ƒë“¤
                relevant_areas = [area for area in related_areas if area in all_product_areas or area in all_selected_areas]
                
                if relevant_areas:
                    if indicator == "ë…¸í™” ì–µì œ ë¶„ì„ì§€ìˆ˜":
                        detailed_analysis.append(f"ë…¸í™” ì–µì œì™€ ê´€ë ¨í•˜ì—¬ {', '.join(relevant_areas[:3])} ë“±ì˜ ì˜ì—­ì—ì„œ ê°œì„ ì´ í•„ìš”í•œ ìƒí™©ì…ë‹ˆë‹¤.")
                    elif indicator == "ë§Œì„±ì§ˆí™˜ ì–µì œ ë¶„ì„ì§€ìˆ˜":
                        detailed_analysis.append(f"ë§Œì„±ì§ˆí™˜ ì˜ˆë°©ì„ ìœ„í•´ {', '.join(relevant_areas[:3])} ë“±ì˜ ê´€ë¦¬ê°€ ì¤‘ìš”í•œ ì‹œì ì…ë‹ˆë‹¤.")
                    elif indicator == "ê·¼ìœ¡ ë°¸ëŸ°ìŠ¤ ë¶„ì„ì§€ìˆ˜":
                        detailed_analysis.append(f"ê·¼ìœ¡ ê±´ê°• ìœ ì§€ë¥¼ ìœ„í•´ {', '.join(relevant_areas[:3])} ë“±ì˜ ì˜ì—­ì— íŠ¹ë³„í•œ ê´€ì‹¬ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if detailed_analysis:
            explanation_parts.extend(detailed_analysis)
            explanation_parts.append("")
        
        # ì¶”ê°€ ì„¤ëª… - ë‹¤ë¥¸ ì—°ê´€ ì˜ì—­ë“¤ì— ëŒ€í•œ ì„¤ëª… (ë” í’ë¶€í•˜ê²Œ)
        other_areas = []
        for indicator in problematic_indicators.keys():
            if indicator in health_relationships:
                related_areas = health_relationships[indicator]
                # ìš°ì„ ìˆœìœ„ ì˜ì—­ì„ ì œì™¸í•œ ë‹¤ë¥¸ ì˜ì—­ë“¤
                other_related = [area for area in related_areas if area not in unique_priority_areas and (area in all_selected_areas or area in all_product_areas)]
                other_areas.extend(other_related)
        
        # ì¤‘ë³µ ì œê±°
        unique_other_areas = list(set(other_areas))
        
        if unique_other_areas:
            other_areas_text = ', '.join(unique_other_areas[:4])  # ìµœëŒ€ 4ê°œê¹Œì§€
            explanation_parts.append(f"ì´ì™€ í•¨ê»˜ {other_areas_text} ë“±ì˜ ì˜ì—­ë„ ì¢…í•©ì ìœ¼ë¡œ ê´€ë¦¬í•˜ì‹œë©´ ë”ìš± íš¨ê³¼ì ì¸ ê±´ê°• ê°œì„ ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ì´ëŸ¬í•œ ì˜ì—­ë“¤ì€ ì„œë¡œ ì—°ê´€ë˜ì–´ ìˆì–´ í•¨ê»˜ ê´€ë¦¬í•  ë•Œ ì‹œë„ˆì§€ íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            explanation_parts.append("")
        
        # ìƒí™œìŠµê´€ ê°œì„  ê¶Œì¥ì‚¬í•­ ì¶”ê°€
        lifestyle_recommendations = []
        if "í˜ˆí–‰ ê°œì„ " in all_product_areas or "í˜ˆí–‰ ê°œì„ " in all_selected_areas:
            lifestyle_recommendations.append("ê·œì¹™ì ì¸ ìœ ì‚°ì†Œ ìš´ë™")
        if "í•­ì‚°í™”" in all_product_areas or "í•­ì‚°í™”" in all_selected_areas:
            lifestyle_recommendations.append("ì¶©ë¶„í•œ ìˆ˜ë©´ê³¼ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬")
        if "ê·¼ë ¥(ê·¼ìœ¡)" in all_product_areas or "ê·¼ë ¥(ê·¼ìœ¡)" in all_selected_areas:
            lifestyle_recommendations.append("ì ì ˆí•œ ë‹¨ë°±ì§ˆ ì„­ì·¨ì™€ ê·¼ë ¥ ìš´ë™")
        if "í˜ˆì¤‘ ì§€ì§ˆ ê°œì„ " in all_product_areas or "í˜ˆì¤‘ ì§€ì§ˆ ê°œì„ " in all_selected_areas:
            lifestyle_recommendations.append("ê· í˜• ì¡íŒ ì‹ë‹¨ê³¼ ê¸ˆì—°")
        
        explanation_parts.append("---")
        explanation_parts.append("")
        
        return '\n'.join(explanation_parts)

    def recommend_products(self, assessments: Dict[str, str], physiology_network: List[str], health_concerns: List[str], user_input: str = "", user_data: Dict = None) -> tuple:
        """ìƒˆë¡œìš´ ì¶”ì²œ ë¡œì§ì˜ ë©”ì¸ í•¨ìˆ˜ - DataFrameê³¼ LLM ì„¤ëª…ì„ í•¨ê»˜ ë°˜í™˜"""
        
        # 'ì¢‹ìŒ'ì´ ì•„ë‹Œ ê±´ê°•ì§€í‘œë§Œ í•„í„°ë§
        active_health_indicators = [k for k, v in assessments.items() if v in ["ì£¼ì˜", "ê´€ë¦¬"]]
        
        # ëª¨ë“  ê±´ê°• ì§€í‘œê°€ 'ì¢‹ìŒ'ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
        if not active_health_indicators:
            # ê±´ê°• ì§€í‘œëŠ” ê³ ë ¤í•˜ì§€ ì•Šê³  ì¸ì²´ ìƒë¦¬ ë„¤íŠ¸ì›Œí¬ì™€ ê±´ê°• ë¶„ì•¼ë§Œìœ¼ë¡œ ì¶”ì²œ
            final_products = self._recommend_for_all_good_health(physiology_network, health_concerns)
            # ëª¨ë“  ê±´ê°•ì§€í‘œê°€ ì¢‹ìŒì¸ ê²½ìš°ì˜ LLM ì„¤ëª… ìƒì„±
            llm_explanation = self._generate_explanation_for_good_health(physiology_network, health_concerns, final_products)
            return final_products, llm_explanation
        
        # ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸”ì—ì„œ ì œí’ˆ ì¶”ì²œ
        selected_products, product_scores = self.get_products_from_classification(
            active_health_indicators, physiology_network, health_concerns
        )
        
        # ì œí’ˆ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        product_details = self.get_product_details(selected_products)
        
        # ë¶„ë¥˜ê¸°ì¤€ ì •ë³´ ì¡°íšŒ
        product_classification = self.get_product_classification_info(selected_products)
        
        # ìµœì¢… ì œí’ˆ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 7ê°œ ì œí•œ)
        final_products = pd.DataFrame()
        seen_products = set()
        
        # ì ìˆ˜ ì •ë³´ë¥¼ DataFrameì— ì¶”ê°€
        if not product_details.empty:
            # ì‹¤ì œ final_scoreë¥¼ ìš°ì„ ìˆœìœ„ ì ìˆ˜ë¡œ ì‚¬ìš©
            product_details['ìš°ì„ ìˆœìœ„_ì ìˆ˜'] = product_details['ì œí’ˆëª…'].map(
                lambda x: product_scores.get(x, {}).get('final_score', 0)
            )
            product_details['ë§¤ì¹­_ê·¼ê±°'] = product_details['ì œí’ˆëª…'].map(
                lambda x: self._create_matching_reason(x, product_scores.get(x, {}), physiology_network, health_concerns)
            )
            product_details['í•´ë‹¹_ê±´ê°•ì§€í‘œ'] = product_details['ì œí’ˆëª…'].map(
                lambda x: ', '.join(product_classification.get(x, {}).get('health_indicators', set()))
            )
            product_details['í•´ë‹¹_ê´€ë¦¬ì˜ì—­'] = product_details['ì œí’ˆëª…'].map(
                lambda x: ', '.join(product_classification.get(x, {}).get('management_areas', set()))
            )
            product_details['í•´ë‹¹_ì›ë£Œ'] = product_details['ì œí’ˆëª…'].map(
                lambda x: ', '.join(product_classification.get(x, {}).get('ingredients', set()))
            )
            
            # selected_products ìˆœì„œë¥¼ ìœ ì§€í•˜ë©´ì„œ ì •ë ¬
            # selected_productsëŠ” final_score ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆìŒ
            product_details['ì›ë³¸_ìˆœì„œ'] = product_details['ì œí’ˆëª…'].map(
                lambda x: selected_products.index(x) if x in selected_products else 999
            )
            product_details = product_details.sort_values('ì›ë³¸_ìˆœì„œ')
            
            # ìµœëŒ€ 7ê°œê¹Œì§€ë§Œ ì„ íƒ
            for _, product in product_details.iterrows():
                if len(final_products) < 7 and product['ì œí’ˆëª…'] not in seen_products:
                    final_products = pd.concat([final_products, pd.DataFrame([product])], ignore_index=True)
                    seen_products.add(product['ì œí’ˆëª…'])
                    
                if len(final_products) >= 7:
                    break
        
        # LLMì„ í™œìš©í•œ ê°œì¸í™”ëœ ì¶”ì²œ ê·¼ê±° ìƒì„±
        llm_explanation = ""
        if not final_products.empty:
            recommended_product_names = final_products['ì œí’ˆëª…'].tolist()
            llm_explanation = self.generate_personalized_recommendation_explanation(
                assessments, physiology_network, health_concerns, recommended_product_names, product_scores, user_data
            )
        
        return final_products, llm_explanation
    
    def _create_matching_reason(self, product_name: str, score_data: Dict, physiology_network: List[str], health_concerns: List[str]) -> str:
        """ë§¤ì¹­ ê·¼ê±° í…ìŠ¤íŠ¸ ìƒì„±"""
        reasons = []
        
        if 'ë…¸í™” ì–µì œ ë¶„ì„ì§€ìˆ˜' in score_data.get('health_indicators', set()) and 'ë§Œì„±ì§ˆí™˜ ì–µì œ ë¶„ì„ì§€ìˆ˜' in score_data.get('health_indicators', set()):
            reasons.append("1ìˆœìœ„: ë…¸í™”ì–µì œ+ë§Œì„±ì§ˆí™˜ ëª¨ë‘ í¬í•¨")
        elif 'ë…¸í™” ì–µì œ ë¶„ì„ì§€ìˆ˜' in score_data.get('health_indicators', set()) or 'ë§Œì„±ì§ˆí™˜ ì–µì œ ë¶„ì„ì§€ìˆ˜' in score_data.get('health_indicators', set()):
            reasons.append("2ìˆœìœ„: ë…¸í™”ì–µì œ/ë§Œì„±ì§ˆí™˜ ì¤‘ í•˜ë‚˜ í¬í•¨")
        
        physiology_matches = score_data.get('physiology_matches', 0)
        if physiology_matches == len(physiology_network) and len(physiology_network) > 0:
            reasons.append(f"ì¸ì²´ìƒë¦¬ë„¤íŠ¸ì›Œí¬ ëª¨ë‘ ë§¤ì¹­({physiology_matches}ê°œ)")
        elif physiology_matches > 0:
            reasons.append(f"ì¸ì²´ìƒë¦¬ë„¤íŠ¸ì›Œí¬ ì¼ë¶€ ë§¤ì¹­({physiology_matches}ê°œ)")
        
        concern_matches = score_data.get('concern_matches', 0)
        if concern_matches > 0:
            reasons.append(f"ê±´ê°•ë¶„ì•¼ ë§¤ì¹­({concern_matches}ê°œ)")
        
        return ", ".join(reasons) if reasons else "ê¸°íƒ€ ë§¤ì¹­"

    def _create_matching_reason_safe(self, product_name: str, score_data: Dict, physiology_network: List[str], health_concerns: List[str]) -> str:
        """ì•ˆì „í•œ ë§¤ì¹­ ê·¼ê±° í…ìŠ¤íŠ¸ ìƒì„± (ì˜¤ë¥˜ ë°©ì§€)"""
        try:
            reasons = []
            
            # ê±´ê°•ì§€í‘œ ë§¤ì¹­ í™•ì¸ (ì•ˆì „í•œ ë°©ì‹)
            best_combo = score_data.get('best_combo', '')
            if best_combo:
                if 'ë…¸í™” ì–µì œ ë¶„ì„ì§€ìˆ˜' in best_combo and 'ë§Œì„±ì§ˆí™˜ ì–µì œ ë¶„ì„ì§€ìˆ˜' in best_combo:
                    reasons.append("1ìˆœìœ„: ë…¸í™”ì–µì œ+ë§Œì„±ì§ˆí™˜ ëª¨ë‘ í¬í•¨")
                elif 'ë…¸í™” ì–µì œ ë¶„ì„ì§€ìˆ˜' in best_combo or 'ë§Œì„±ì§ˆí™˜ ì–µì œ ë¶„ì„ì§€ìˆ˜' in best_combo:
                    reasons.append("2ìˆœìœ„: ë…¸í™”ì–µì œ/ë§Œì„±ì§ˆí™˜ ì¤‘ í•˜ë‚˜ í¬í•¨")
                else:
                    reasons.append("ê±´ê°•ì§€í‘œ ë§¤ì¹­")
            
            # ê´€ë¦¬ì˜ì—­ ë§¤ì¹­ í™•ì¸
            physiology_matches = score_data.get('physiology_matches', 0)
            if physiology_matches == len(physiology_network) and len(physiology_network) > 0:
                reasons.append(f"ì¸ì²´ìƒë¦¬ë„¤íŠ¸ì›Œí¬ ì™„ì „ë§¤ì¹­({physiology_matches}ê°œ)")
            elif physiology_matches > 0:
                reasons.append(f"ì¸ì²´ìƒë¦¬ë„¤íŠ¸ì›Œí¬ ë§¤ì¹­({physiology_matches}ê°œ)")
            
            concern_matches = score_data.get('concern_matches', 0)
            if concern_matches > 0:
                reasons.append(f"ê±´ê°•ë¶„ì•¼ ë§¤ì¹­({concern_matches}ê°œ)")
            
            # ì •í™•í•œ ë§¤ì¹­ ì—¬ë¶€ í‘œì‹œ
            if score_data.get('best_is_exact_match', False):
                reasons.append("ì •í™•í•œ ë§¤ì¹­")
            
            return ", ".join(reasons) if reasons else "ê¸°ë³¸ ë§¤ì¹­"
            
        except Exception as e:
            return f"ë§¤ì¹­ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"

    def _recommend_for_all_good_health(self, physiology_network: List[str], health_concerns: List[str]) -> pd.DataFrame:
        """ëª¨ë“  ê±´ê°• ì§€í‘œê°€ 'ì¢‹ìŒ'ì¸ ê²½ìš° ì¸ì²´ ìƒë¦¬ ë„¤íŠ¸ì›Œí¬ì™€ ê±´ê°• ë¶„ì•¼ë§Œìœ¼ë¡œ ì œí’ˆ ì¶”ì²œ"""
        
        # ì„ íƒëœ ëª¨ë“  ê´€ë¦¬ ì˜ì—­
        all_selected_areas = set(physiology_network + health_concerns)
        
        if not all_selected_areas:
            return pd.DataFrame()
        
        # ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸”ì—ì„œ ì„ íƒëœ ê´€ë¦¬ ì˜ì—­ì— í•´ë‹¹í•˜ëŠ” ì œí’ˆë“¤ ì¡°íšŒ (ê±´ê°•ì§€í‘œ í¬í•¨)
        areas_filter = ', '.join(f"'{area}'" for area in all_selected_areas)
        
        query = f"""
        SELECT "ì œí’ˆëª…", "ê±´ê°•ì§€í‘œ", "ê´€ë¦¬ í•„ìš” ì˜ì—­", "ì›ë£Œ"
        FROM "ë¶„ë¥˜ê¸°ì¤€"
        WHERE "ê´€ë¦¬ í•„ìš” ì˜ì—­" IN ({areas_filter})
        """
        
        classification_df = pd.read_sql(query, con=self.engine)
        
        if classification_df.empty:
            return pd.DataFrame()
        
        # ì œí’ˆë³„ ê´€ë¦¬ ì˜ì—­ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° ë° ê±´ê°•ì§€í‘œ ìˆ˜ì§‘
        product_scores = {}
        
        for _, row in classification_df.iterrows():
            product_name = row['ì œí’ˆëª…']
            health_indicator = row['ê±´ê°•ì§€í‘œ']
            management_area = row['ê´€ë¦¬ í•„ìš” ì˜ì—­']
            
            if product_name not in product_scores:
                product_scores[product_name] = {
                    'management_areas': set(),
                    'health_indicators': set(),  # ê±´ê°•ì§€í‘œ ì¶”ê°€
                    'ingredients': set(),  # ì›ë£Œ ì¶”ê°€
                    'physiology_matches': 0,
                    'concern_matches': 0,
                    'total_matches': 0
                }
            
            product_scores[product_name]['management_areas'].add(management_area)
            product_scores[product_name]['health_indicators'].add(health_indicator)  # ê±´ê°•ì§€í‘œ ì €ì¥
            
            # ì›ë£Œ ì •ë³´ ì¶”ê°€ (nullì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
            if pd.notna(row.get('ì›ë£Œ')):
                product_scores[product_name]['ingredients'].add(row['ì›ë£Œ'])
            
            # ì¸ì²´ ìƒë¦¬ ë„¤íŠ¸ì›Œí¬ ë§¤ì¹­
            if management_area in physiology_network:
                product_scores[product_name]['physiology_matches'] += 1
            
            # ì‹ ê²½ ì¨ì•¼ í•  ê±´ê°• ë¶„ì•¼ ë§¤ì¹­
            if management_area in health_concerns:
                product_scores[product_name]['concern_matches'] += 1
            
            # ì „ì²´ ë§¤ì¹­ ê°œìˆ˜
            product_scores[product_name]['total_matches'] += 1
        
        # ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì œí’ˆ ì •ë ¬
        sorted_products = []
        
        for product_name, score_data in product_scores.items():
            # ìµœì¢… ì ìˆ˜ ê³„ì‚° (ì¸ì²´ ìƒë¦¬ ë„¤íŠ¸ì›Œí¬ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
            final_score = (
                score_data['physiology_matches'] * 10 +  # ì¸ì²´ ìƒë¦¬ ë„¤íŠ¸ì›Œí¬ ê°€ì¤‘ì¹˜
                score_data['concern_matches'] * 5 +      # ê±´ê°• ë¶„ì•¼ ê°€ì¤‘ì¹˜
                score_data['total_matches'] * 2          # ì „ì²´ ë§¤ì¹­ ë³´ë„ˆìŠ¤
            )
            
            score_data['final_score'] = final_score
            sorted_products.append((product_name, score_data))
        
        # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_products.sort(key=lambda x: x[1]['final_score'], reverse=True)
        
        # ìƒìœ„ 7ê°œ ì œí’ˆ ì„ íƒ
        top_products = sorted_products[:7]
        selected_product_names = [product[0] for product in top_products]
        
        # ì œí’ˆ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        product_details = self.get_product_details(selected_product_names)
        
        # ë¶„ë¥˜ê¸°ì¤€ ì •ë³´ ì¡°íšŒ
        product_classification = self.get_product_classification_info(selected_product_names)
        
        if not product_details.empty:
            # ì ìˆ˜ ì •ë³´ë¥¼ DataFrameì— ì¶”ê°€
            product_details['ìš°ì„ ìˆœìœ„_ì ìˆ˜'] = product_details['ì œí’ˆëª…'].map(
                lambda x: next((score_data['final_score'] for name, score_data in top_products if name == x), 0)
            )
            product_details['ë§¤ì¹­_ê·¼ê±°'] = product_details['ì œí’ˆëª…'].map(
                lambda x: self._create_matching_reason_for_good_health(x, product_scores.get(x, {}), physiology_network, health_concerns)
            )
            product_details['í•´ë‹¹_ê±´ê°•ì§€í‘œ'] = product_details['ì œí’ˆëª…'].map(
                lambda x: ', '.join(product_scores.get(x, {}).get('health_indicators', set()))
            )
            product_details['í•´ë‹¹_ê´€ë¦¬ì˜ì—­'] = product_details['ì œí’ˆëª…'].map(
                lambda x: ', '.join(product_classification.get(x, {}).get('management_areas', set()))
            )
            product_details['í•´ë‹¹_ì›ë£Œ'] = product_details['ì œí’ˆëª…'].map(
                lambda x: ', '.join(product_scores.get(x, {}).get('ingredients', set()))
            )
            
            # ìš°ì„ ìˆœìœ„ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
            product_details = product_details.sort_values('ìš°ì„ ìˆœìœ„_ì ìˆ˜', ascending=False)
        
        return product_details

    def _create_matching_reason_for_good_health(self, product_name: str, score_data: Dict, physiology_network: List[str], health_concerns: List[str]) -> str:
        """ëª¨ë“  ê±´ê°• ì§€í‘œê°€ 'ì¢‹ìŒ'ì¸ ê²½ìš°ì˜ ë§¤ì¹­ ê·¼ê±° í…ìŠ¤íŠ¸ ìƒì„±"""
        reasons = []
        
        physiology_matches = score_data.get('physiology_matches', 0)
        if physiology_matches == len(physiology_network) and len(physiology_network) > 0:
            reasons.append(f"ì¸ì²´ìƒë¦¬ë„¤íŠ¸ì›Œí¬ ì™„ì „ë§¤ì¹­({physiology_matches}ê°œ)")
        elif physiology_matches > 0:
            reasons.append(f"ì¸ì²´ìƒë¦¬ë„¤íŠ¸ì›Œí¬ ë§¤ì¹­({physiology_matches}ê°œ)")
        
        concern_matches = score_data.get('concern_matches', 0)
        if concern_matches == len(health_concerns) and len(health_concerns) > 0:
            reasons.append(f"ê±´ê°•ë¶„ì•¼ ì™„ì „ë§¤ì¹­({concern_matches}ê°œ)")
        elif concern_matches > 0:
            reasons.append(f"ê±´ê°•ë¶„ì•¼ ë§¤ì¹­({concern_matches}ê°œ)")
        
        if not reasons:
            reasons.append("ê±´ê°• ìœ ì§€ ë° ì˜ˆë°© ëª©ì ")
        
        return ", ".join(reasons)


    def analyze_user_health_data(self, user_data: Dict) -> Dict[str, str]:
        """ì‚¬ìš©ìì˜ ì‹¤ì œ ê±´ê°• ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì²´ì ì¸ ê±´ê°• ìƒíƒœ ì„¤ëª… ìƒì„±"""
        analysis = {}
        
        # ê¸°ë³¸ ì •ë³´
        age = user_data.get('age', 0)
        sex = user_data.get('sex', 1)  # 1: ë‚¨ì„±, 2: ì—¬ì„±
        bmi = user_data.get('he_bmi', 0)
        
        # í˜ˆì•• ë¶„ì„
        sbp = user_data.get('sbp', 0)  # ìˆ˜ì¶•ê¸° í˜ˆì••
        dbp = user_data.get('dbp', 0)  # ì´ì™„ê¸° í˜ˆì••
        
        if sbp >= 140 or dbp >= 90:
            analysis['í˜ˆì••'] = f"ìˆ˜ì¶•ê¸° í˜ˆì•• {sbp}mmHg, ì´ì™„ê¸° í˜ˆì•• {dbp}mmHgë¡œ ê³ í˜ˆì•• ë²”ìœ„ì— í•´ë‹¹í•˜ì—¬ í˜ˆì•• ì¡°ì ˆì´ í•„ìš”í•©ë‹ˆë‹¤."
        elif sbp >= 130 or dbp >= 80:
            analysis['í˜ˆì••'] = f"ìˆ˜ì¶•ê¸° í˜ˆì•• {sbp}mmHg, ì´ì™„ê¸° í˜ˆì•• {dbp}mmHgë¡œ ê³ í˜ˆì•• ì „ë‹¨ê³„ë¡œ í˜ˆì•• ê´€ë¦¬ê°€ ê¶Œì¥ë©ë‹ˆë‹¤."
        
        # ê°„ ê¸°ëŠ¥ ë¶„ì„
        gpt = user_data.get('gpt', 0)  # ALT
        got = user_data.get('got', 0)  # AST
        
        if gpt > 40 or got > 40:
            analysis['ê°„ê±´ê°•'] = f"ALT {gpt}U/L, AST {got}U/Lë¡œ ì •ìƒ ë²”ìœ„ë¥¼ ì´ˆê³¼í•˜ì—¬ ê°„ ê¸°ëŠ¥ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."
        elif gpt > 30 or got > 30:
            analysis['ê°„ê±´ê°•'] = f"ALT {gpt}U/L, AST {got}U/Lë¡œ ì •ìƒ ìƒí•œì— ê·¼ì ‘í•˜ì—¬ ê°„ ê±´ê°• ê´€ë¦¬ê°€ ê¶Œì¥ë©ë‹ˆë‹¤."
        
        # í˜ˆì¤‘ ì§€ì§ˆ ë¶„ì„
        tc = user_data.get('tc', 0)  # ì´ ì½œë ˆìŠ¤í…Œë¡¤
        ldl = user_data.get('ldl', 0)  # LDL ì½œë ˆìŠ¤í…Œë¡¤
        hdl = user_data.get('hdl', 0)  # HDL ì½œë ˆìŠ¤í…Œë¡¤
        tg = user_data.get('tg', 0)  # ì¤‘ì„±ì§€ë°©
        
        lipid_issues = []
        if tc >= 240:
            lipid_issues.append(f"ì´ ì½œë ˆìŠ¤í…Œë¡¤ {tc}mg/dL (ê³ ìœ„í—˜)")
        elif tc >= 200:
            lipid_issues.append(f"ì´ ì½œë ˆìŠ¤í…Œë¡¤ {tc}mg/dL (ê²½ê³„)")
            
        if ldl >= 160:
            lipid_issues.append(f"LDL ì½œë ˆìŠ¤í…Œë¡¤ {ldl}mg/dL (ê³ ìœ„í—˜)")
        elif ldl >= 130:
            lipid_issues.append(f"LDL ì½œë ˆìŠ¤í…Œë¡¤ {ldl}mg/dL (ê²½ê³„)")
            
        if (sex == 1 and hdl < 40) or (sex == 2 and hdl < 50):
            lipid_issues.append(f"HDL ì½œë ˆìŠ¤í…Œë¡¤ {hdl}mg/dL (ë‚®ìŒ)")
            
        if tg >= 200:
            lipid_issues.append(f"ì¤‘ì„±ì§€ë°© {tg}mg/dL (ë†’ìŒ)")
        elif tg >= 150:
            lipid_issues.append(f"ì¤‘ì„±ì§€ë°© {tg}mg/dL (ê²½ê³„)")
        
        if lipid_issues:
            analysis['í˜ˆì¤‘ì§€ì§ˆ'] = "í˜ˆì¤‘ ì§€ì§ˆ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤: " + ", ".join(lipid_issues)
        
        # í˜ˆë‹¹ ë¶„ì„
        glu = user_data.get('glu', 0)
        if glu >= 126:
            analysis['í˜ˆë‹¹'] = f"ê³µë³µí˜ˆë‹¹ {glu}mg/dLë¡œ ë‹¹ë‡¨ë³‘ ë²”ìœ„ì— í•´ë‹¹í•˜ì—¬ í˜ˆë‹¹ ì¡°ì ˆì´ ì‹œê¸‰í•©ë‹ˆë‹¤."
        elif glu >= 100:
            analysis['í˜ˆë‹¹'] = f"ê³µë³µí˜ˆë‹¹ {glu}mg/dLë¡œ ë‹¹ë‡¨ë³‘ ì „ë‹¨ê³„ë¡œ í˜ˆë‹¹ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        
        # ì²´ì¤‘ ë° ì²´ì„±ë¶„ ë¶„ì„
        if bmi >= 30:
            analysis['ì²´ì¤‘'] = f"BMI {bmi}ë¡œ ë¹„ë§Œ ìƒíƒœë¡œ ì²´ì§€ë°© ê°ì†Œê°€ í•„ìš”í•©ë‹ˆë‹¤."
        elif bmi >= 25:
            analysis['ì²´ì¤‘'] = f"BMI {bmi}ë¡œ ê³¼ì²´ì¤‘ ìƒíƒœë¡œ ì²´ì¤‘ ê´€ë¦¬ê°€ ê¶Œì¥ë©ë‹ˆë‹¤."
        elif bmi < 18.5:
            analysis['ì²´ì¤‘'] = f"BMI {bmi}ë¡œ ì €ì²´ì¤‘ ìƒíƒœë¡œ ì˜ì–‘ ê· í˜•ê³¼ ê·¼ë ¥ ì¦ì§„ì´ í•„ìš”í•©ë‹ˆë‹¤."
        
        # ê·¼ìœ¡ëŸ‰ ë¶„ì„
        skeletal_muscle = user_data.get('skeletal_muscle_mass', 0)
        per_bodyfat = user_data.get('per_bodyfat', 0)
        
        if per_bodyfat > 25 and sex == 1:  # ë‚¨ì„±
            analysis['ê·¼ìœ¡'] = f"ì²´ì§€ë°©ë¥  {per_bodyfat}%ë¡œ ë†’ì•„ ê·¼ë ¥ ì¦ì§„ê³¼ ì²´ì§€ë°© ê°ì†Œê°€ í•„ìš”í•©ë‹ˆë‹¤."
        elif per_bodyfat > 30 and sex == 2:  # ì—¬ì„±
            analysis['ê·¼ìœ¡'] = f"ì²´ì§€ë°©ë¥  {per_bodyfat}%ë¡œ ë†’ì•„ ê·¼ë ¥ ì¦ì§„ê³¼ ì²´ì§€ë°© ê°ì†Œê°€ í•„ìš”í•©ë‹ˆë‹¤."
        
        # ìƒí™œìŠµê´€ ë¶„ì„
        smok_dur = user_data.get('smok_dur', 0)
        sleep_time = user_data.get('sleep_time', 0)
        
        lifestyle_issues = []
        if smok_dur > 0:
            lifestyle_issues.append(f"{smok_dur}ë…„ê°„ì˜ í¡ì—°ìœ¼ë¡œ í•­ì‚°í™” ë° í˜ˆí–‰ ê°œì„ ì´ ì¤‘ìš”í•©ë‹ˆë‹¤")
        
        if sleep_time < 7:
            lifestyle_issues.append(f"ìˆ˜ë©´ì‹œê°„ {sleep_time}ì‹œê°„ìœ¼ë¡œ ë¶€ì¡±í•˜ì—¬ ìˆ˜ë©´ ê±´ê°• ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        if lifestyle_issues:
            analysis['ìƒí™œìŠµê´€'] = ". ".join(lifestyle_issues)
        
        return analysis

    def generate_personalized_recommendation_explanation(self, assessments: Dict[str, str], physiology_network: List[str], health_concerns: List[str], recommended_products: List[str], product_scores: Dict, user_data: Dict = None) -> str:
        """LLMì„ í™œìš©í•˜ì—¬ ê°œì¸í™”ëœ ì œí’ˆ ì¶”ì²œ ê·¼ê±° ìƒì„± - ì‚¬ìš©ì ë°ì´í„° ê¸°ë°˜ ê°œì¸í™”"""
        
        # ë¬¸ì œê°€ ìˆëŠ” ê±´ê°•ì§€í‘œë§Œ ì¶”ì¶œ
        problematic_indicators = {k: v for k, v in assessments.items() if v in ["ì£¼ì˜", "ê´€ë¦¬"]}
        
        # ì‚¬ìš©ì ë°ì´í„° ë¶„ì„ (ìˆëŠ” ê²½ìš°)
        user_health_analysis = {}
        if user_data:
            user_health_analysis = self.analyze_user_health_data(user_data)
        
        # ì œí’ˆë³„ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        product_details = self.get_product_details(recommended_products)
        product_classification = self.get_product_classification_info(recommended_products)
        
        # ê±´ê°•ì§€í‘œì™€ ê´€ë¦¬ì˜ì—­ ì—°ê´€ê´€ê³„ ì¡°íšŒ
        health_relationships = self.get_health_indicator_relationships()
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
ì‚¬ìš©ìì˜ ê±´ê°• ìƒíƒœ ë¶„ì„:
- ê±´ê°• ì§€í‘œ: {', '.join([f"{k}({v})" for k, v in problematic_indicators.items()])}
- ì¸ì²´ ìƒë¦¬ ë„¤íŠ¸ì›Œí¬ ê´€ì‹¬ ì˜ì—­: {', '.join(physiology_network) if physiology_network else 'ì—†ìŒ'}
- ê³ ë ¤í•˜ê³  ì‹¶ì€ ê±´ê°• ë¶„ì•¼: {', '.join(health_concerns) if health_concerns else 'ì—†ìŒ'}
"""

        # ì‚¬ìš©ì ì‹¤ì œ ê±´ê°• ë°ì´í„° ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        if user_health_analysis:
            prompt += f"""
ì‚¬ìš©ìì˜ ì‹¤ì œ ê±´ê°• ë°ì´í„° ë¶„ì„:
"""
            if user_data:
                age = user_data.get('age', 0)
                sex = "ë‚¨ì„±" if user_data.get('sex', 1) == 1 else "ì—¬ì„±"
                prompt += f"- ê¸°ë³¸ì •ë³´: {age}ì„¸ {sex}\n"
            
            for category, analysis in user_health_analysis.items():
                prompt += f"- {category}: {analysis}\n"

        prompt += """
ê±´ê°•ì§€í‘œë³„ ì—°ê´€ ê´€ë¦¬ì˜ì—­:
"""
        
        # ê° ê±´ê°•ì§€í‘œì™€ ì—°ê´€ëœ ê´€ë¦¬ì˜ì—­ ì •ë³´ ì¶”ê°€
        for indicator, status in problematic_indicators.items():
            if indicator in health_relationships:
                related_areas = health_relationships[indicator]
                prompt += f"- {indicator}({status}): {', '.join(related_areas)}\n"
        
        prompt += f"""

ì¶”ì²œëœ ì œí’ˆë“¤ê³¼ ìƒì„¸ ì •ë³´:
"""
        
        # ì œí’ˆì„ ê¸°ë³¸ ë² ì´ìŠ¤(1-3ìœ„)ì™€ ì¶”ê°€ ë³´ê°•(4-7ìœ„)ìœ¼ë¡œ êµ¬ë¶„
        base_products = recommended_products[:3]
        additional_products = recommended_products[3:7] if len(recommended_products) > 3 else []
        
        prompt += "ê¸°ë³¸ ë² ì´ìŠ¤ ì œí’ˆ (1-3ìœ„):\n"
        for i, product_name in enumerate(base_products, 1):
            if product_name in product_scores:
                score_data = product_scores[product_name]
                product_info = product_details[product_details['ì œí’ˆëª…'] == product_name].iloc[0] if not product_details.empty else None
                classification_info = product_classification.get(product_name, {})
                
                prompt += f"""
{i}. {product_name}
   - í•´ë‹¹ ê±´ê°•ì§€í‘œ: {', '.join(classification_info.get('health_indicators', set()))}
   - ê´€ë¦¬ í•„ìš” ì˜ì—­: {', '.join(classification_info.get('management_areas', set()))}
   - **ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸” ì£¼ìš” ì›ë£Œ**: {', '.join(classification_info.get('ingredients', set())) if classification_info.get('ingredients') else 'ì •ë³´ ì—†ìŒ'}
   - ì‹ì•½ì²˜ ì¸ì • ê¸°ëŠ¥ì„±: {product_info['ì‹ì•½ì²˜ ì¸ì • ê¸°ëŠ¥ì„±'] if product_info is not None else 'ì •ë³´ ì—†ìŒ'}
   - ì£¼ìš” íŠ¹ì§•: {product_info['ì£¼ìš” íŠ¹ì§•'] if product_info is not None else 'ì •ë³´ ì—†ìŒ'}
   - ì›ì¬ë£Œ: {product_info['ì›ì¬ë£Œ'] if product_info is not None else 'ì •ë³´ ì—†ìŒ'}
   - ê±´ê°•ì§€í‘œ ë§¤ì¹­: {score_data.get('best_match_count', 0)}ê°œ
   - ì¸ì²´ìƒë¦¬ë„¤íŠ¸ì›Œí¬ ë§¤ì¹­: {score_data.get('physiology_matches', 0)}ê°œ
   - ê±´ê°•ë¶„ì•¼ ë§¤ì¹­: {score_data.get('concern_matches', 0)}ê°œ
"""
        
        if additional_products:
            prompt += "\nì¶”ê°€ ë³´ê°• ì œí’ˆ (4-7ìœ„):\n"
            for i, product_name in enumerate(additional_products, 4):
                if product_name in product_scores:
                    score_data = product_scores[product_name]
                    product_info = product_details[product_details['ì œí’ˆëª…'] == product_name].iloc[0] if not product_details.empty else None
                    classification_info = product_classification.get(product_name, {})
                    
                    prompt += f"""
{i}. {product_name}
   - í•´ë‹¹ ê±´ê°•ì§€í‘œ: {', '.join(classification_info.get('health_indicators', set()))}
   - ê´€ë¦¬ í•„ìš” ì˜ì—­: {', '.join(classification_info.get('management_areas', set()))}
   - **ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸” ì£¼ìš” ì›ë£Œ**: {', '.join(classification_info.get('ingredients', set())) if classification_info.get('ingredients') else 'ì •ë³´ ì—†ìŒ'}
   - ì‹ì•½ì²˜ ì¸ì • ê¸°ëŠ¥ì„±: {product_info['ì‹ì•½ì²˜ ì¸ì • ê¸°ëŠ¥ì„±'] if product_info is not None else 'ì •ë³´ ì—†ìŒ'}
   - ì£¼ìš” íŠ¹ì§•: {product_info['ì£¼ìš” íŠ¹ì§•'] if product_info is not None else 'ì •ë³´ ì—†ìŒ'}
   - ì›ì¬ë£Œ: {product_info['ì›ì¬ë£Œ'] if product_info is not None else 'ì •ë³´ ì—†ìŒ'}
   - ê±´ê°•ì§€í‘œ ë§¤ì¹­: {score_data.get('best_match_count', 0)}ê°œ
   - ì¸ì²´ìƒë¦¬ë„¤íŠ¸ì›Œí¬ ë§¤ì¹­: {score_data.get('physiology_matches', 0)}ê°œ
   - ê±´ê°•ë¶„ì•¼ ë§¤ì¹­: {score_data.get('concern_matches', 0)}ê°œ
"""
        
        # ê¸°ë³¸ ì œí’ˆê³¼ ë³´ê°• ì œí’ˆì˜ ì°¨ë³„ì  ë¶„ì„ì„ ìœ„í•œ ì •ë³´
        if additional_products:
            prompt += f"""

ê¸°ë³¸ ì œí’ˆ vs ë³´ê°• ì œí’ˆ ì°¨ë³„ì  ë¶„ì„:
"""
            # ê¸°ë³¸ ì œí’ˆë“¤ì˜ ì›ë£Œì™€ ê´€ë¦¬ì˜ì—­ ìˆ˜ì§‘
            base_ingredients = set()
            base_management_areas = set()
            base_health_indicators = set()
            
            for product_name in base_products:
                if product_name in product_classification:
                    base_ingredients.update(product_classification[product_name].get('ingredients', set()))
                    base_management_areas.update(product_classification[product_name].get('management_areas', set()))
                    base_health_indicators.update(product_classification[product_name].get('health_indicators', set()))
            
            prompt += f"ê¸°ë³¸ ì œí’ˆë“¤ì´ ì»¤ë²„í•˜ëŠ” ì˜ì—­:\n"
            prompt += f"- ì£¼ìš” ì›ë£Œ: {', '.join(base_ingredients) if base_ingredients else 'ì •ë³´ ì—†ìŒ'}\n"
            prompt += f"- ê´€ë¦¬ ì˜ì—­: {', '.join(base_management_areas) if base_management_areas else 'ì •ë³´ ì—†ìŒ'}\n"
            prompt += f"- ê±´ê°•ì§€í‘œ: {', '.join(base_health_indicators) if base_health_indicators else 'ì •ë³´ ì—†ìŒ'}\n"
            
            # ë³´ê°• ì œí’ˆë“¤ë§Œì˜ ê³ ìœ í•œ íŠ¹ì§• ë¶„ì„
            prompt += f"\në³´ê°• ì œí’ˆë“¤ì˜ ì¶”ê°€ ë³´ì™„ ì˜ì—­:\n"
            for product_name in additional_products:
                if product_name in product_classification:
                    classification_info = product_classification[product_name]
                    
                    # ê¸°ë³¸ ì œí’ˆì— ì—†ëŠ” ê³ ìœ  ì›ë£Œ
                    unique_ingredients = classification_info.get('ingredients', set()) - base_ingredients
                    # ê¸°ë³¸ ì œí’ˆì— ì—†ëŠ” ê³ ìœ  ê´€ë¦¬ì˜ì—­
                    unique_areas = classification_info.get('management_areas', set()) - base_management_areas
                    
                    if unique_ingredients or unique_areas:
                        prompt += f"- {product_name}: "
                        if unique_ingredients:
                            prompt += f"ê³ ìœ  ì›ë£Œ({', '.join(unique_ingredients)}) "
                        if unique_areas:
                            prompt += f"ì¶”ê°€ ê´€ë¦¬ì˜ì—­({', '.join(unique_areas)})"
                        prompt += "\n"

        # ê°œì¸í™”ëœ ì¶”ì²œ ë¡œì§ ì„¤ëª…ì„ ìœ„í•œ ì¶”ê°€ ì •ë³´
        prompt += f"""

ì¶”ì²œ ë¡œì§ ê°œì¸í™” ì •ë³´:
- ì´ ì¶”ì²œ ì œí’ˆ ìˆ˜: {len(recommended_products)}ê°œ
- ê¸°ë³¸ ë² ì´ìŠ¤ ì œí’ˆ: {len(base_products)}ê°œ
- ì¶”ê°€ ë³´ê°• ì œí’ˆ: {len(additional_products)}ê°œ
- ì‚¬ìš©ì ê±´ê°•ì§€í‘œ ë¬¸ì œ ê°œìˆ˜: {len(problematic_indicators)}ê°œ
- ì„ íƒí•œ ê´€ì‹¬ì˜ì—­ ì´ ê°œìˆ˜: {len(physiology_network) + len(health_concerns)}ê°œ
"""

        # ì œí’ˆë³„ ë§¤ì¹­ ì ìˆ˜ ë¶„ì„
        if product_scores:
            prompt += "\nì œí’ˆë³„ ê°œì¸ ë§ì¶¤ ì ìˆ˜ ë¶„ì„:\n"
            for i, product_name in enumerate(recommended_products[:5], 1):  # ìƒìœ„ 5ê°œë§Œ
                if product_name in product_scores:
                    score_data = product_scores[product_name]
                    prompt += f"- {product_name}: ì´ì  {score_data.get('final_score', 0)}ì  (ê±´ê°•ì§€í‘œ {score_data.get('best_match_count', 0)}ê°œ ë§¤ì¹­, ê´€ì‹¬ì˜ì—­ {score_data.get('physiology_matches', 0) + score_data.get('concern_matches', 0)}ê°œ ë§¤ì¹­)\n"

        prompt += """

ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©ì ê°œì¸ ë°ì´í„°ì— ê¸°ë°˜í•œ í†µí•©ëœ ë§ì¶¤í˜• ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

## ğŸ” ì§„ë‹¨ ê²°ê³¼

ì‚¬ìš©ìë‹˜ì˜ ì‹¤ì œ ê±´ê°• ë°ì´í„°(í˜ˆì••, ê°„ê¸°ëŠ¥, í˜ˆì¤‘ì§€ì§ˆ, í˜ˆë‹¹, ì²´ì„±ë¶„ ë“±)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê±´ê°•ì§€í‘œ ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ê³ , 
ì™œ íŠ¹ì • ê´€ë¦¬ì˜ì—­ì´ ìš°ì„ ì ìœ¼ë¡œ í•„ìš”í•œì§€ ì˜í•™ì  ê·¼ê±°ì™€ í•¨ê»˜ ëª…ì‹œí•˜ì„¸ìš”. ë˜í•œ ì‚¬ìš©ìë‹˜ì˜ ê°œì¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ 
ë§ì¶¤í˜• ì¶”ì²œ ë¡œì§ì„ ì ìš©í•œ êµ¬ì²´ì ì¸ ì¶”ì²œ ê·¼ê±°ì™€ ìš°ì„ ìˆœìœ„ ê²°ì • ê³¼ì •ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”:
- ìš°ì„ ìˆœìœ„ë¥¼ ì •í•˜ëŠ” ê¸°ì¤€ ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ê³  ì‹œì‘í•˜ì„¸ìš”.
- ê°ê°ì˜ ìš°ì„ ìˆœìœ„ ê²°ì • ê·¼ê±°
- ì„ íƒí•˜ì‹  ê´€ì‹¬ ì˜ì—­ê³¼ ì‹¤ì œ ê±´ê°• ìƒíƒœì˜ ì—°ê´€ì„± ë¶„ì„
- ëª¨ë“  ê´€ì‹¬ ì˜ì—­ì„ ë‚˜ì—´í•˜ì§€ ë§ê³  ì‚¬ìš©ìê°€ ì„ íƒí•œ ê´€ì‹¬ ì˜ì—­ë§Œ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
- ì‹¤ì œ ê±´ê°• ë°ì´í„°(í˜ˆì••, ê°„ê¸°ëŠ¥, í˜ˆì¤‘ì§€ì§ˆ ë“±)ê°€ ì œí’ˆ ì„ íƒì— ë¯¸ì¹œ ì˜í–¥
- ì‚¬ìš©ìë‹˜ë§Œì˜ ê±´ê°• ê´€ë¦¬ ìš°ì„ ìˆœìœ„ì™€ ì œí’ˆ ë§¤ì¹­ ê³¼ì •

## ğŸ’Š ê¸°ë³¸ ë² ì´ìŠ¤ ì œí’ˆ

ê° ì œí’ˆë§ˆë‹¤ ### ì œí’ˆëª… ì‘ì„± í›„ í•œ ë‹¨ë½ì˜ ì„œìˆ ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ìŒì„ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ ì“°ë˜, ê° ì œí’ˆë§ˆë‹¤ ë¬¸ì¥ê³¼ í‘œí˜„ì„ ë§¤ë²ˆ ë‹¤ë¥´ê²Œ êµ¬ì„±í•˜ì—¬ ì¤‘ë³µì„ í”¼í•˜ì„¸ìš”:
- ì œí’ˆëª…ê³¼ í•µì‹¬ ê¸°ëŠ¥ì„±
- ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸”ì˜ ì£¼ìš” ì›ë£Œì™€ ê° ì›ë£Œì˜ êµ¬ì²´ì  íš¨ê³¼(í•´ë‹¹ ê±´ê°•ì§€í‘œì™€ì˜ ì—°ê³„ í¬í•¨)
- ì‹ì•½ì²˜ ì¸ì • ê¸°ëŠ¥ì„±, ì£¼ìš” íŠ¹ì§•
- ê±´ê°•ì§€í‘œ ë§¤ì¹­ ë° ì„ íƒ ê·¼ê±°ë¥¼ ì›ë£Œì˜ íš¨ê³¼ì™€ ì—°ê²°
- ì‚¬ìš©ì ìƒí™©ì— ë§ì¶˜ ì ìš© í¬ì¸íŠ¸(ê´€ì‹¬ ì˜ì—­ê³¼ì˜ ì—°ê²°)
- ê° ê¸°ë³¸ ë² ì´ìŠ¤ ì œí’ˆì— ë§¤ì¹­ëœ ê±´ê°•ì§€í‘œì™€ ê´€ë¦¬ í•„ìš” ì˜ì—­ì„ ë¬¸ì¥ ì†ì—ì„œ ë°˜ë“œì‹œ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤.

## ğŸ’ªğŸ» ë³´ê°• ì œí’ˆ

ê° ë³´ê°• ì œí’ˆë„ ### ì œí’ˆëª… ì‘ì„± í›„ í•œ ë‹¨ë½ì˜ ì„œìˆ ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ìŒì„ ë‹´ë˜, ê¸°ë³¸ ë² ì´ìŠ¤ì™€ì˜ ì°¨ë³„ì ì„ ì¤‘ì‹¬ìœ¼ë¡œ ê° ì œí’ˆë§ˆë‹¤ ì¤‘ë³µ ì—†ì´ ì „ê°œí•˜ì„¸ìš”:
- ê¸°ë³¸ ë² ì´ìŠ¤ì™€ì˜ ì°¨ì´ì™€ ë³´ì™„ í¬ì¸íŠ¸
- ê³ ìœ  ì›ë£Œ(ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸” ê¸°ì¤€)ì™€ ê·¸ ì›ë£Œê°€ ì œê³µí•˜ëŠ” ì¶”ê°€ íš¨ê³¼(í•´ë‹¹ ê±´ê°•ì§€í‘œì™€ì˜ ì—°ê³„ í¬í•¨)
- ê¸°ë³¸ ì œí’ˆìœ¼ë¡œ ì»¤ë²„ë˜ì§€ ì•ŠëŠ” ì˜ì—­ì„ ì–´ë–»ê²Œ ë³´ì™„í•˜ëŠ”ì§€ì™€ ì‹œë„ˆì§€
- ì‹ì•½ì²˜ ì¸ì • ê¸°ëŠ¥ì„±, ì£¼ìš” íŠ¹ì§•
 - ì›ë£Œë¥¼ ë‚˜ì—´ë§Œ í•˜ì§€ ë§ê³ , ìµœì†Œ 2ê°œ ì´ìƒì˜ "ì›ë£Œâ†’íš¨ê³¼" ë¬¸ì¥ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”. ì˜ˆ) "ë£¨í…Œì¸ì€ ì²­ìƒ‰ê´‘ìœ¼ë¡œ ì¸í•œ ë§ë§‰ ì‚°í™” ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë‚®ì¶° ì‹œê° ê¸°ëŠ¥ ìœ ì§€ì— ê¸°ì—¬í•©ë‹ˆë‹¤. ì•„ìŠ¤íƒ€ì”í‹´ì€ ê°•í•œ í•­ì‚°í™”ë ¥ìœ¼ë¡œ ë…¸í™” ì–µì œ ì§€í‘œ ê°œì„ ì— íš¨ê³¼ì ì…ë‹ˆë‹¤."
 - ê° ë³´ê°• ì œí’ˆì— ë§¤ì¹­ëœ ê±´ê°•ì§€í‘œì™€ ê´€ë¦¬ í•„ìš” ì˜ì—­ì„ ë¬¸ì¥ ì†ì—ì„œ ë°˜ë“œì‹œ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤.
 - ì‚¬ìš©ì ê´€ì‹¬ ì˜ì—­ê³¼ì˜ ì—°ê²° ë° ì ìš© í¬ì¸íŠ¸
 - ë™ì¼í•œ ë¬¸ì¥/í‘œí˜„/ê·¼ê±° ë°˜ë³µ ê¸ˆì§€

ì‘ì„± ê·œì¹™:
- "~í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤" í‘œí˜„ ê¸ˆì§€ (ìµœëŒ€ 1íšŒë§Œ ì‚¬ìš©)
- "ê°œì„ ", "íš¨ê³¼ì " ë“± ë‹¤ì–‘í•œ í‘œí˜„ í™œìš©
- ì¤‘ë³µ í‘œí˜„ ìµœì†Œí™” (ê°™ì€ ë‹¨ì–´/ë¬¸ì¥ íŒ¨í„´ ë°˜ë³µ ê¸ˆì§€)
- ê°™ì€ ë‚´ìš©ì„ ë‹¤ë¥¸ ì œí’ˆì—ì„œ ë°˜ë³µ ì„¤ëª…í•˜ì§€ ë§ ê²ƒ(ë‚´ìš©Â·í‘œí˜„Â·ê·¼ê±° ëª¨ë‘ ì¤‘ë³µ ê¸ˆì§€)
- ì œí’ˆë³„ë¡œ ë…ë¦½ëœ ë¬¸ë‹¨ êµ¬ì„±
- ê° ë¬¸ë‹¨ì€ 3-4ë¬¸ì¥ ì´ë‚´ë¡œ ì œí•œ
- ê° ì œí’ˆ ë¬¸ë‹¨ì€ 150ì ì´ìƒìœ¼ë¡œ ì‘ì„±
- ìì—°ìŠ¤ëŸ½ê³  ë‹¤ì–‘í•œ ë¬¸ì²´ ì‚¬ìš©

í•„ìˆ˜ ì¤€ìˆ˜ì‚¬í•­:
- ë°˜ë“œì‹œ 'ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ'ì´ë¼ëŠ” ìš©ì–´ë§Œ ì‚¬ìš© ('ê±´ê°• ê¸°ëŠ¥ ë³´ì¡°ì œ' ê¸ˆì§€)
- ì‹ì•½ì²˜ ì¸ì • ê¸°ëŠ¥ì„±ì„ ë°”íƒ•ìœ¼ë¡œë§Œ íš¨ê³¼ ì„¤ëª…
- ê³¼í•™ì Â·ê·œì œ ê·¼ê±°ê°€ ë¶ˆëª…í™•í•œ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
- ë°ì´í„°ë² ì´ìŠ¤ì— ëª…ì‹œëœ ì›ë£Œë§Œ ì–¸ê¸‰
- ê¸°ëŠ¥ì„±, ì›ë£Œ, ì›ì¬ë£Œ ë“±ì—ì„œ ì–»ëŠ” íš¨ê³¼ë¥¼ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ëª…ì‹œí•  ê²ƒ
- ì™¸êµ­ì–´ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€(ì˜ì–´, í•œêµ­ì–´ë§Œ í—ˆìš©)
- ê° ì œí’ˆ ì„¤ëª…ì—ëŠ” 'ì‹ì•½ì²˜ ì¸ì • ê¸°ëŠ¥ì„±', 'ì£¼ìš” íŠ¹ì§•', 'ì›ì¬ë£Œ'(ì œí’ˆì •ë³´), 'ì›ë£Œ'(ë¶„ë¥˜ê¸°ì¤€)ë¥¼ ë°˜ë“œì‹œ í¬í•¨
"""

        try:
            # ìºì‹œ ì¡°íšŒ
            cache_payload = {
                "model": "llama-3.3-70b-versatile",
                "system": "ë‹¹ì‹ ì€ ê°œì¸ ë§ì¶¤í˜• ê±´ê°• ì œí’ˆ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
                "prompt": prompt,
                "temperature": 0.4,
            }
            cache_key = self._build_cache_key(cache_payload, prefix="personalized")
            cached = self._read_cache(cache_key)
            if cached:
                return cached.strip()

            chat_completion = self.groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",  # ë” ì •êµí•œ ë¶„ì„ì„ ìœ„í•´ í° ëª¨ë¸ ì‚¬ìš©
                messages=[
                    {"role": "system", "content": """ë‹¹ì‹ ì€ ê°œì¸ ë§ì¶¤í˜• ê±´ê°• ì œí’ˆ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

í•µì‹¬ ì›ì¹™:
- ì‚¬ìš©ì ê°œì¸ ë°ì´í„°ì— ê¸°ë°˜í•œ ë§ì¶¤í˜• ì¶”ì²œ ë¡œì§ ì„¤ëª…
- ê° ì‚¬ìš©ìì˜ ê±´ê°• ìƒíƒœ, ê´€ì‹¬ ì˜ì—­, ì‹¤ì œ ê±´ê°• ìˆ˜ì¹˜ë¥¼ ë°˜ì˜í•œ ê°œì¸í™”ëœ ê·¼ê±° ì œì‹œ
- **ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸”ì˜ ì›ë£Œ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ì œí’ˆ ì„¤ëª…**
- ì œí’ˆë³„ë¡œ ë…ë¦½ëœ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±í•˜ì—¬ ì½ê¸° ì‰½ê²Œ ì‘ì„±
- ë‹¤ì–‘í•œ í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
- ê° ì œí’ˆì˜ ê³ ìœ í•œ íŠ¹ì§•ê³¼ ê°œì¸ë³„ ì„ íƒ ê·¼ê±°ë¥¼ ëª…í™•íˆ êµ¬ë¶„

ê°œì¸í™” ìš”êµ¬ì‚¬í•­:
- ì¶”ì²œ ë¡œì§ ì„¤ëª…ì€ ë°˜ë“œì‹œ í•´ë‹¹ ì‚¬ìš©ìì˜ êµ¬ì²´ì ì¸ ë°ì´í„°ë¥¼ ë°˜ì˜í•´ì•¼ í•¨
- ê±´ê°•ì§€í‘œ ìƒíƒœ, ì„ íƒí•œ ê´€ì‹¬ ì˜ì—­, ì‹¤ì œ ê±´ê°• ìˆ˜ì¹˜ê°€ ì œí’ˆ ì„ íƒì— ë¯¸ì¹œ ì˜í–¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
- ë™ì¼í•œ ì œí’ˆì´ë¼ë„ ì‚¬ìš©ìì— ë”°ë¼ ë‹¤ë¥¸ ì¶”ì²œ ê·¼ê±°ì™€ ìš°ì„ ìˆœìœ„ ì„¤ëª… ì œê³µ
- ì‚¬ìš©ìë³„ ê±´ê°• ê´€ë¦¬ ìš°ì„ ìˆœìœ„ì™€ ì œí’ˆ ë§¤ì¹­ ê³¼ì •ì„ ê°œì¸í™”í•˜ì—¬ ì„¤ëª…

ë³´ê°• ì œí’ˆ ì°¨ë³„ì  ì„¤ëª… ìš”êµ¬ì‚¬í•­:
- ë³´ê°• ì œí’ˆì€ ê¸°ë³¸ ë² ì´ìŠ¤ ì œí’ˆê³¼ì˜ ëª…í™•í•œ ì°¨ë³„ì ì„ ì œì‹œí•´ì•¼ í•¨
- **ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸” ê¸°ì¤€ìœ¼ë¡œ ê¸°ë³¸ ì œí’ˆì— ì—†ëŠ” ê³ ìœ  ì›ë£Œì™€ ê·¸ ì›ë£Œì˜ ì¶”ê°€ì ì¸ ê±´ê°• íš¨ê³¼ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…**
- ê¸°ë³¸ ì œí’ˆìœ¼ë¡œ ì»¤ë²„ë˜ì§€ ì•ŠëŠ” ê±´ê°• ì˜ì—­ì„ ì–´ë–»ê²Œ ë³´ì™„í•˜ëŠ”ì§€ ëª…ì‹œ
- ê¸°ë³¸ ì œí’ˆê³¼ ë³´ê°• ì œí’ˆì˜ ì‹œë„ˆì§€ íš¨ê³¼ë‚˜ ìƒí˜¸ ë³´ì™„ ê´€ê³„ë¥¼ ì„¤ëª…
- ì‚¬ìš©ìì˜ ê±´ê°• ìƒíƒœì—ì„œ ë³´ê°• ì œí’ˆì´ í•„ìš”í•œ êµ¬ì²´ì ì¸ ì´ìœ ë¥¼ ì œì‹œ

ê·œì œ ë° ìš©ì–´ ì¤€ìˆ˜:
- ë°˜ë“œì‹œ 'ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ'ì´ë¼ëŠ” ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš” ('ê±´ê°• ê¸°ëŠ¥ ë³´ì¡°ì œ' ì‚¬ìš© ê¸ˆì§€)
- ì‹ì•½ì²˜ì—ì„œ ì¸ì •í•œ ê¸°ëŠ¥ì„±ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”
- ê³¼í•™ì Â·ê·œì œ ê·¼ê±°ê°€ ë¶ˆëª…í™•í•œ í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ëŠ” ì›ë£Œë‚˜ ì„±ë¶„ì€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
- í•œìë‚˜ ì¼ë³¸ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”

í‘œí˜„ ë‹¤ì–‘í™”:
- "ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤" ëŒ€ì‹  "íš¨ê³¼ì ì…ë‹ˆë‹¤", "ê°œì„ ë©ë‹ˆë‹¤" ë“± í™œìš©
- "ê°œì„ í•˜ëŠ” ë°" ëŒ€ì‹  "í–¥ìƒì‹œí‚¤ë©°", "ê°•í™”í•˜ê³ ", "ê´€ë¦¬í•˜ì—¬" ë“± ì‚¬ìš©
- ê°™ì€ íŒ¨í„´ì˜ ë¬¸ì¥ êµ¬ì¡° ë°˜ë³µ ê¸ˆì§€
- ìì—°ìŠ¤ëŸ½ê³  ë‹¤ì–‘í•œ ë¬¸ì²´ë¡œ ì‘ì„±

ê¸ˆì§€ì‚¬í•­:
- "~í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤" ê³¼ë„í•œ ë°˜ë³µ (ìµœëŒ€ 1íšŒ)
- "ê°ê¸° ë‹¤ë¥¸ ê±´ê°• íš¨ê³¼ë¥¼ ì§€ì›í•œë‹¤"ì™€ ê°™ì€ í¬ê´„ì /ëª¨í˜¸í•œ í‘œí˜„
- "ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì˜ì—­ì…ë‹ˆë‹¤" ê°™ì€ ë°˜ë³µ í‘œí˜„
- ëª¨ë“  ì œí’ˆì— ë™ì¼í•œ ì„¤ëª… íŒ¨í„´ ì ìš©
- ê°™ì€ ë™ì‚¬ë‚˜ í˜•ìš©ì‚¬ì˜ ì—°ì† ì‚¬ìš©
- í•œì, ì¼ë³¸ì–´, ì¤‘êµ­ì–´ ì‚¬ìš©
- "ì¶”ê°€ì ì¸ ì§€ì›ì„ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤" ê°™ì€ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„
- ê°™ì€ ë¬¸ì¥ì´ë‚˜ êµ¬ë¬¸ì˜ ë°˜ë³µ
- ë‚´ìš©ì´ ì¤‘ê°„ì— ëŠê¸°ê±°ë‚˜ ë¯¸ì™„ì„±ìœ¼ë¡œ ëë‚˜ëŠ” ê²ƒ
 - ì›ë£ŒÂ·ê¸°ëŠ¥ì„±Â·ì›ì¬ë£Œë¥¼ ë‹¨ìˆœ ë‚˜ì—´ë§Œ í•˜ê³  íš¨ê³¼ë¥¼ ì„œìˆ í•˜ì§€ ì•ŠëŠ” í–‰ìœ„

ì‘ì„± ì™„ì„±ë„:
- ë°˜ë“œì‹œ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ëë‚´ì•¼ í•¨
- ëª¨ë“  ì„¹ì…˜ì„ ë¹ ì§ì—†ì´ ì‘ì„±í•´ì•¼ í•¨
- ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ìš´ í•œêµ­ì–´ ì‚¬ìš©
- ë¶ˆí•„ìš”í•œ êµ°ë”ë”ê¸° ì œê±°, ê°„ê²°í•˜ê³  ë°€ë„ ìˆê²Œ ì‘ì„±"""},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1600,  # í† í° ì ˆê°(ë‚´ìš© ìœ ì§€ì— ì¶©ë¶„)
                temperature=0.4   # ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ì„ ìœ„í•´ ì ì ˆíˆ ì¡°ì •
            )
            
            content = chat_completion.choices[0].message.content.strip()
            self._write_cache(cache_key, content)
            return content
            
        except Exception as e:
            return f"ê°œì¸í™”ëœ ì¶”ì²œ ê·¼ê±° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def _generate_explanation_for_good_health(self, physiology_network: List[str], health_concerns: List[str], final_products: pd.DataFrame) -> str:
        """ëª¨ë“  ê±´ê°•ì§€í‘œê°€ ì¢‹ìŒì¸ ê²½ìš°ì˜ LLM ì„¤ëª… ìƒì„±"""
        
        if final_products.empty:
            return "ì¶”ì²œí•  ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤."
        
        prompt = f"""
ì‚¬ìš©ìì˜ ê±´ê°• ìƒíƒœ:
- ëª¨ë“  ê±´ê°• ì§€í‘œ(ë…¸í™” ì–µì œ ë¶„ì„ì§€ìˆ˜, ê·¼ìœ¡ ë°¸ëŸ°ìŠ¤ ë¶„ì„ì§€ìˆ˜, ë§Œì„±ì§ˆí™˜ ì–µì œ ë¶„ì„ì§€ìˆ˜)ê°€ 'ì¢‹ìŒ' ìƒíƒœ
- ì¸ì²´ ìƒë¦¬ ë„¤íŠ¸ì›Œí¬ ê´€ì‹¬ ì˜ì—­: {', '.join(physiology_network) if physiology_network else 'ì—†ìŒ'}
- ê³ ë ¤í•˜ê³  ì‹¶ì€ ê±´ê°• ë¶„ì•¼: {', '.join(health_concerns) if health_concerns else 'ì—†ìŒ'}

ì¶”ì²œëœ ì œí’ˆë“¤:
"""
        
        for i, (_, row) in enumerate(final_products.iterrows(), 1):
            prompt += f"""
{i}. {row['ì œí’ˆëª…']}
   - í•´ë‹¹ ê´€ë¦¬ì˜ì—­: {row.get('í•´ë‹¹_ê´€ë¦¬ì˜ì—­', 'ì •ë³´ ì—†ìŒ')}
   - ì£¼ìš” ì›ë£Œ: {row.get('í•´ë‹¹_ì›ë£Œ', 'ì •ë³´ ì—†ìŒ')}
   - ì›ì¬ë£Œ: {row.get('ì›ì¬ë£Œ', 'ì •ë³´ ì—†ìŒ')}
   - ì‹ì•½ì²˜ ì¸ì • ê¸°ëŠ¥ì„±: {row.get('ì‹ì•½ì²˜ ì¸ì • ê¸°ëŠ¥ì„±', 'ì •ë³´ ì—†ìŒ')}
   - ì£¼ìš” íŠ¹ì§•: {row.get('ì£¼ìš” íŠ¹ì§•', 'ì •ë³´ ì—†ìŒ')}
"""
        
        prompt += """
ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì´ í†µí•©ëœ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

## ğŸ” ì§„ë‹¨ ê²°ê³¼

í˜„ì¬ ê±´ê°• ìƒíƒœê°€ ì–‘í˜¸í•œ ì‚¬ìš©ìì—ê²Œ ì´ëŸ¬í•œ ì œí’ˆë“¤ì´ ì™œ ë„ì›€ì´ ë˜ëŠ”ì§€ ì˜ˆë°© ë° ìœ ì§€ ê´€ì ì—ì„œ ì„¤ëª…í•˜ê³ , ì„ íƒëœ ê´€ì‹¬ ì˜ì—­ê³¼ ì œí’ˆ ì¶”ì²œ ë¡œì§ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

## ğŸ’Š ê°œì¸ ë§ì¶¤ ê±´ê°• ì œí’ˆ ì¶”ì²œ

ê° ì¶”ì²œ ì œí’ˆì€ í•œ ë‹¨ë½ì˜ ì„œìˆ ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ìŒì„ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ ì“°ê³ , ì œí’ˆ ê°„ ì¤‘ë³µì„ í”¼í•˜ì„¸ìš”:
- ë¶„ë¥˜ê¸°ì¤€ í…Œì´ë¸”ì˜ ì£¼ìš” ì›ë£Œì™€ ê° ì›ë£Œì˜ êµ¬ì²´ì  íš¨ê³¼(í•´ë‹¹ ê±´ê°•ì§€í‘œì™€ì˜ ì—°ê³„ í¬í•¨)
- ì‹ì•½ì²˜ ì¸ì • ê¸°ëŠ¥ì„±, ì£¼ìš” íŠ¹ì§•, ì›ì¬ë£Œ(ì œí’ˆì •ë³´ í…Œì´ë¸”)
+ - í•´ë‹¹ ì œí’ˆì— ë§¤ì¹­ëœ ê±´ê°•ì§€í‘œì™€ ê´€ë¦¬ í•„ìš” ì˜ì—­ì„ ë¬¸ì¥ ì†ì—ì„œ ë¶„ëª…íˆ ì–¸ê¸‰
 - ì‚¬ìš©ì ê´€ì‹¬ ì˜ì—­ê³¼ì˜ ì—°ê²° ë° ì ìš© í¬ì¸íŠ¸
 - ë™ì¼í•œ ë¬¸ì¥/í‘œí˜„/ê·¼ê±° ë°˜ë³µ ê¸ˆì§€

## ğŸ“‹ ê°œì¸ë³„ ê±´ê°• ê´€ë¦¬ ë°©í–¥

ì„ íƒëœ ê´€ì‹¬ ì˜ì—­ê³¼ ì œí’ˆë“¤ì˜ ì—°ê´€ì„±ì„ ì›ë£Œ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ê³ , ì¥ê¸°ì ì¸ ê±´ê°• ê´€ë¦¬ ì „ëµì„ ì›ë£Œì˜ íš¨ê³¼ì™€ ì—°ê²°í•˜ì—¬ ì œì‹œí•´ì£¼ì„¸ìš”.

ì„¤ëª…ì€ ì˜ˆë°© ì˜í•™ì  ê´€ì ì—ì„œ ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        try:
            # ìºì‹œ ì¡°íšŒ
            cache_payload = {
                "model": "llama-3.3-70b-versatile",
                "system": "ë‹¹ì‹ ì€ ì˜ˆë°© ì˜í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
                "prompt": prompt,
                "temperature": 0.4,
            }
            cache_key = self._build_cache_key(cache_payload, prefix="goodhealth")
            cached = self._read_cache(cache_key)
            if cached:
                return cached.strip()

            chat_completion = self.groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì˜ˆë°© ì˜í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê±´ê°•í•œ ì‚¬ìš©ìì—ê²Œ ê±´ê°• ìœ ì§€ ë° ì˜ˆë°©ì„ ìœ„í•œ ì œí’ˆ ì¶”ì²œ ê·¼ê±°ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1200,  # í† í° ì ˆê°(ë‚´ìš© ìœ ì§€)
                temperature=0.4   # ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„
            )
            
            content = chat_completion.choices[0].message.content.strip()
            self._write_cache(cache_key, content)
            return content
            
        except Exception as e:
            return f"ê±´ê°• ìœ ì§€ ì¶”ì²œ ê·¼ê±° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"





    def format_recommendations(self, result_df: pd.DataFrame, llm_explanation: str = "") -> str:
        """ì¶”ì²œ ê²°ê³¼ë¥¼ ì›¹ í˜ì´ì§€ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        if result_df.empty:
            return "ì¶”ì²œí•  ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤."
        
        formatted_output = ""
        
        # LLM ì„¤ëª…ì´ ìˆìœ¼ë©´ ë¨¼ì € í‘œì‹œ (ì§„ë‹¨ + ì¶”ì²œ ë¡œì§ + ê¸°ë³¸ ì œí’ˆ + ë³´ê°• ì œí’ˆ + ê°œì¸ë³„ ê´€ë¦¬ ë°©í–¥)
        if llm_explanation:
            formatted_output += f"{llm_explanation}\n\n"
        
        return formatted_output